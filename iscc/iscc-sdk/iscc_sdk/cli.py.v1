import os
from datetime import datetime, timezone
import json, jwt
import base58, base64
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Iterator, Optional, Tuple
from loguru import logger as log
import typer
from pathlib import Path
import iscc_core as ic
import iscc_sdk as idk
from rich.console import Console
from rich.progress import (
    Progress,
    BarColumn,
    TextColumn,
    TransferSpeedColumn,
    TimeRemainingColumn,
    DownloadColumn,
)
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import ec
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import hashes
from datetime import datetime
import rfc3161ng
import requests

console = Console()
app = typer.Typer(add_completion=False, no_args_is_help=True)

def get_timestamp(data):

    # Hash the file data
    hasher = hashes.Hash(hashes.SHA512(), default_backend())
    hasher.update(base64.urlsafe_b64decode(data))
    hash_value = hasher.finalize()

    rt = rfc3161ng.RemoteTimestamper('https://freetsa.org/tsr')
    tst = rt.timestamp(data=data)
    # print(rfc3161ng.get_timestamp(tst))

    return tst

def get_timestamp_response(timestamp_request):
    headers = {
        'Content-Type': 'application/timestamp-query'
    }

    try:
        response = requests.post('https://freetsa.org/tsr', data=timestamp_request, headers=headers)
        response.raise_for_status()

        print(f"Timestamp response received successfully")
        return response.content
    except requests.exceptions.RequestException as e:
        print(f"Error getting timestamp response: {e}")


def _log_formatter(record: dict) -> str:  # pragma: no cover
    """Log message formatter"""
    color_map = {
        "TRACE": "blue",
        "DEBUG": "cyan",
        "INFO": "bold",
        "SUCCESS": "bold green",
        "WARNING": "yellow",
        "ERROR": "bold red",
        "CRITICAL": "bold white on red",
    }
    lvl_color = color_map.get(record["level"].name, "cyan")
    return (
        "[not bold green]{time:YYYY/MM/DD HH:mm:ss}[/not bold green] | {module:<12} | {line:<3} | {level.icon}"
        + f"  - [{lvl_color}]{{message}}[/{lvl_color}]"
    )


log.add(console.print, level="DEBUG", format=_log_formatter, colorize=True)


def iter_unprocessed(path, root_path=None):
    # type: (str|Path, Optional[str|Path]) -> Iterator[Tuple[Path, int]]
    """
    Walk directory tree recursively with deterministic ordering and yield tuples of file metadata.

    Metadata = (relpath, size)

    - path: pathlib.Path object
    - size: integer file size in number of bytes

    File-entries are yielded in reproducible and deterministic order (bottom-up). Symlink and
    processed files are ignored silently.

    Implementation Note: We use os.scandir to reduce the number of syscalls for metadata collection.
    """
    root_path = Path(root_path or path)
    with os.scandir(path) as entries:
        # Sort the entries
        sorted_entries = sorted(entries, key=lambda e: e.name)

        # Separate directories and files
        dirs = [entry for entry in sorted_entries if entry.is_dir()]
        files = [entry for entry in sorted_entries if entry.is_file()]

        # Recursively process directories first (bottom-up traversal)
        for dir_entry in dirs:
            yield from iter_unprocessed(Path(dir_entry.path), root_path=root_path)

        # Process files in the current directory
        for file_entry in files:
            file_path = Path(file_entry)
            # Ignore result files
            if file_path.name.endswith(".iscc.json") or file_path.name.endswith(".iscc.mp7sig"):
                continue
            # Ignore files that have results
            if Path(file_path.as_posix() + ".iscc.json").exists():
                continue
            file_size = file_entry.stat().st_size
            yield file_path, file_size


def process_file(fp: Path):
    idk.sdk_opts.video_store_mp7sig = True
    try:
        return fp, idk.code_iscc(fp.as_posix())
    except Exception as e:
        return fp, e

def generate_and_store_key(file_path):
    # Generate an ECDSA key pair using the P-256 curve
    private_key = ec.generate_private_key(ec.SECP256R1(), default_backend())

    # Serialize the private key to PEM format
    private_key_pem = private_key.private_bytes(
        encoding=serialization.Encoding.PEM,
        format=serialization.PrivateFormat.TraditionalOpenSSL,
        encryption_algorithm=serialization.NoEncryption()
    )

    # Write the private key to the specified file
    with open(file_path, 'wb') as key_file:
        key_file.write(private_key_pem)

    print(f"ECDSA key successfully generated and stored in {file_path}")

def load_key(file_path):
    # Read the private key from the specified file
    with open(file_path, 'rb') as key_file:
        private_key_pem = key_file.read()

    # Deserialize the private key
    private_key = serialization.load_pem_private_key(
        private_key_pem,
        password=None,
        backend=default_backend()
    )

    print(f"ECDSA key successfully loaded from {file_path}")
    return private_key

def base64url_encode(data):
    # Custom base64url encoding function
    return base64.urlsafe_b64encode(data).rstrip(b'=').decode('utf-8')

def create_did_key(public_key):
    # Serialize the public key to JWK format
    jwk = {
        "kty": "EC",
        "crv": "P-256",
        "x": base64url_encode(public_key.public_bytes(
            encoding=serialization.Encoding.X962,
            format=serialization.PublicFormat.UncompressedPoint
        )[:32]),
        "y": base64url_encode(public_key.public_bytes(
            encoding=serialization.Encoding.X962,
            format=serialization.PublicFormat.UncompressedPoint
        )[32:])
    }

    # Serialize the JWK to a JSON string with double quotes
    jwk_json = json.dumps(jwk, separators=(',', ':'), sort_keys=True)
    # print(jwk_json)

    # Encode the JWK JSON string using UTF-8
    encoded_jwk = bytes.fromhex('d1d603') + jwk_json.encode('utf-8')

    # Encode the JWK JSON string in base58btc format
    did_key = 'did:key:z' + base58.b58encode(encoded_jwk).decode()

    return did_key


def sign(header, payload, private_key):
    """
    Sign a JSON

    Args:
    - header (dict): JWS header.
    - payload (dict): JWS payload.
    - private_key_path (str): Path to the private key file in PEM format.

    Returns:
    - str: Encoded JWT.
    """
    # Encode the JWT
    jws = jwt.encode(payload, private_key, algorithm="ES256", headers=header)
    return jws

@app.command()
def createKey(file: Path):
    generate_and_store_key(file)

@app.command()
def loadKey(file: Path):
    key = load_key(file)
    print(create_did_key(key.public_key()))

@app.command()
def create(file: Path):
    """Create ISCC-CODE for single FILE."""
    log.remove()
    if file.is_file() and file.exists():
        result = idk.code_iscc(file.as_posix())
        typer.echo(result.json(indent=2))
    else:
        typer.echo(f"Invalid file path {file}")
        raise typer.Exit(code=1)


@app.command()
def batch(folder: Path, workers: int = os.cpu_count()):  # pragma: no cover
    """Create ISCC-CODEs for files in FOLDER (parallel & recursive)."""
    if not folder.is_dir() or not folder.exists():
        typer.echo(f"Invalid folder {folder}")
        raise typer.Exit(1)

    file_paths = []
    file_sizes = []
    for path, size in iter_unprocessed(folder):
        file_paths.append(path)
        file_sizes.append(size)

    file_sizes_dict = {path: size for path, size in zip(file_paths, file_sizes)}
    total_size = sum(file_sizes)
    progress = Progress(
        TextColumn("[bold blue]Processing {task.fields[dirname]}", justify="right"),
        BarColumn(),
        "[progress.percentage]{task.percentage:>3.1f}%",
        "•",
        DownloadColumn(),
        "•",
        TransferSpeedColumn(),
        "•",
        TimeRemainingColumn(),
        console=console,
    )

    with progress:
        task_id = progress.add_task("Processing", dirname=folder.name, total=total_size)
        with ProcessPoolExecutor(max_workers=workers) as executor:
            futures = [executor.submit(process_file, fp) for fp in file_paths]
            for future in as_completed(futures):
                fp, iscc_meta = future.result()
                if isinstance(iscc_meta, idk.IsccMeta):
                    out_path = Path(fp.as_posix() + ".iscc.json")
                    with out_path.open(mode="wt", encoding="utf-8") as outf:
                        outf.write(iscc_meta.json(indent=2))
                    log.info(f"Finished {fp.name}")
                else:
                    log.error(f"Failed {fp.name}: {iscc_meta}")
                progress.update(task_id, advance=file_sizes_dict[fp], refresh=True)


@app.command()
def install():
    """Install content processing tools."""
    idk.install()


@app.command()
def selftest():
    """Run conformance tests."""
    ic.conformance_selftest()

def remove_null_values(input_dict):
    return {key: value for key, value in input_dict.items() if value is not None}

@app.command()
def cs(key_path, file: Path):
    """Create signed ISCC metadata for single FILE."""
    log.remove()
    key = load_key(key_path)
    print("[*] Private key is loaded")
    did = create_did_key(key.public_key())
    print("[*] DID:", did)
    if file.is_file() and file.exists():
        result = idk.code_iscc(file.as_posix())
        result2 = vars(result)
        iscc_id = ic.gen_iscc_id(result.iscc, 0, did, 0)['iscc']
        result2["iscc_id"] = iscc_id
        print("[*] ISCC ID:", iscc_id)
        result2["wallet"] = did
        result2 = remove_null_values(result2)
        # sign JWS
        timestampRaw = datetime.utcnow()
        timestamp = timestampRaw.replace(microsecond=0, tzinfo=timezone.utc).isoformat()
        header = {"sigT": timestamp, "typ": "dades-z", "kid": did, "crit": ["sigT"], "cty": "ld+json"}
        signedMetadata = sign(header, result2, key)
        file_name = str(file) + '.metadata.' + timestampRaw.strftime("%Y-%m-%dT%H-%M-%SZ") + '.jws'
        with open(file_name, 'w') as file:
            file.write(signedMetadata)
        print("Signed metadata is stored to", file_name)
    else:
        typer.echo(f"Invalid file path {file}")
        raise typer.Exit(code=1)

@app.command()
def cstst(key_path, file: Path):
    """Create signed and timestamped ISCC metadata for single FILE."""
    log.remove()
    key = load_key(key_path)
    print("[*] Private key is loaded")
    did = create_did_key(key.public_key())
    print("[*] DID:", did)
    if file.is_file() and file.exists():
        result = idk.code_iscc(file.as_posix())
        result2 = vars(result)
        iscc_id = ic.gen_iscc_id(result.iscc, 0, did, 0)['iscc']
        result2["iscc_id"] = iscc_id
        print("[*] ISCC ID:", iscc_id)
        result2["wallet"] = did
        result2 = remove_null_values(result2)
        # sign JWS
        encoded_payload = jwt.encode(result2, key='', algorithm=None).split('.')[1]
        tst = get_timestamp(encoded_payload)
        tst_str = rfc3161ng.get_timestamp(tst)
        tst_enc = base64.b64encode(tst)
        print("[*] Timestamp obtained")
        header = {"sigT": tst_str.strftime("%Y-%m-%dT%H:%M:%SZ"), "tst": tst_enc.decode('utf-8'), "typ": "dades-z", "kid": did, "crit": ["sigT"], "cty": "ld+json"}
        signedMetadata = sign(header, result2, key)
        file_name = str(file) + '.metadata+timestamp.' + tst_str.strftime("%Y-%m-%dT%H-%M-%SZ") + '.jws'
        with open(file_name, 'w') as file:
            file.write(signedMetadata)
        print("Signed metadata is stored to", file_name)
    else:
        typer.echo(f"Invalid file path {file}")
        raise typer.Exit(code=1)

@app.command()
def timestamp():
    """Timestamp."""
    rt = rfc3161ng.RemoteTimestamper('https://freetsa.org/tsr')
    tst = rt.timestamp(data=b'John Doe')
    print(rfc3161ng.get_timestamp(tst))

if __name__ == "__main__":  # pragma: no cover
    app()
